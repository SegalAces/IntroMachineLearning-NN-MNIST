{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0b9330",
   "metadata": {},
   "source": [
    "# Machine Learning - Task 6\n",
    "## Neural Network for Mnist dataset\n",
    "### Or segal, ID: 313151862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c635c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f1bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, epochs = 10, batch_size = 16, learning_rate = 0.1, nof_classes = 10, hidden_size_1 = 512, hidden_size_2 = 256, verbose = False):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.nof_classes = nof_classes\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.Verbose = verbose\n",
    "        self.Ws = []\n",
    "        self.biases = []\n",
    "        return\n",
    "    \n",
    "    def xavier_init(self, shape):\n",
    "        fan_in = shape[0]\n",
    "        fan_out = shape[1]\n",
    "        limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "        return np.random.uniform(-limit, limit, shape)\n",
    "    \n",
    "    def init_weights(self, X, y):\n",
    "        if(self.Verbose):\n",
    "            print(\"Starts initializing weights...\")\n",
    "        self.nof_features = X.shape[1]\n",
    "        self.Ws.append(self.xavier_init((self.nof_features, self.hidden_size_1)))\n",
    "        self.biases.append(np.zeros((1, self.hidden_size_1)))\n",
    "        self.Ws.append(self.xavier_init((self.hidden_size_1, self.hidden_size_2)))\n",
    "        self.biases.append(np.zeros((1, self.hidden_size_2)))\n",
    "        self.Ws.append(self.xavier_init((self.hidden_size_2, self.nof_classes)))\n",
    "        self.biases.append(np.zeros((1, self.nof_classes)))\n",
    "        if(self.Verbose):\n",
    "            print(\"Finished initializing weights.\")\n",
    "        return\n",
    "    \n",
    "    def shuffle_data(self, X, y):\n",
    "        # Generate random indices for shuffling\n",
    "        indices = np.random.permutation(len(X))\n",
    "\n",
    "        # Shuffle both arrays based on the indices\n",
    "        shuffled_X = X[indices]\n",
    "        shuffled_y = y[indices]\n",
    "\n",
    "        return shuffled_X, shuffled_y\n",
    "        \n",
    "    def get_batch(self, X, y, start_idx): \n",
    "        # Determine the indices for the current batch\n",
    "        start_idx = start_idx * self.batch_size\n",
    "        \n",
    "        # Adjust the end index if remaining samples are less than batch_size\n",
    "        end_idx = min(start_idx + self.batch_size, X.shape[0])\n",
    "\n",
    "        # Extract the current batch from X and y\n",
    "        batch_X = X[start_idx:end_idx]\n",
    "        batch_y = y[start_idx:end_idx]\n",
    "        \n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def softmax(self, z):    \n",
    "        # Compute the exponential of each element\n",
    "        exp_z = np.exp(z)\n",
    "        \n",
    "        # Compute the sum of exponential values along each row\n",
    "        sum_exp_z = np.sum(exp_z, axis=1, keepdims=True)\n",
    "        \n",
    "        # Compute the softmax probabilities by dividing each exponential value by the sum\n",
    "        softmax_output = exp_z / sum_exp_z\n",
    "        return softmax_output\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def cross_entropy(self, y_true, y_pred, epsilon = 1e-10):\n",
    "        # Clip predicted probabilities to avoid log(0) errors\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Calculate cross-entropy loss\n",
    "        loss = -np.mean(y_true * np.log(y_pred))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        # Calculate the derivative of the ReLU function\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        self.X = X \n",
    "        self.Z1 = (np.dot(self.X, self.Ws[0]) + self.biases[0]) #inputs for hidden layer\n",
    "        \n",
    "        self.A1 = (self.relu(self.Z1)) # outputs of hidden layer 1\n",
    "        self.Z2 = (np.dot(self.A1, self.Ws[1]) + self.biases[1]) # inputs for hidden layer 2\n",
    "        \n",
    "        self.A2 = (self.relu(self.Z2)) # outputs of hidden layer 2\n",
    "        self.Z3 = (np.dot(self.A2, self.Ws[2]) + self.biases[2]) # inputs for output layer \n",
    "    \n",
    "        self.A3 = self.softmax(self.Z3) # network output\n",
    "        return self.A3\n",
    "    \n",
    "    \n",
    "    def back_backpropagation(self, y):\n",
    "        m = self.X.shape[0]\n",
    "        one_hot_y = np.eye(self.nof_classes)[y]\n",
    "        \n",
    "        # computing layer 3\n",
    "        self.dZ3 = (self.A3 - one_hot_y)\n",
    "        dW3 = np.dot(self.A2.T, self.dZ3) / m\n",
    "        dB3 = np.mean(self.dZ3, axis=0, keepdims = True)\n",
    "        \n",
    "        # computing layer 2\n",
    "        self.dZ2 = np.dot(self.dZ3, self.Ws[2].T) * self.relu_derivative(self.Z2)\n",
    "        dW2 = np.dot(self.A1.T, self.dZ2) / m\n",
    "        dB2 = np.mean(self.dZ2, axis=0, keepdims=True)\n",
    "        \n",
    "        # computing layer 1\n",
    "        self.dZ1 = (np.dot(self.dZ2, self.Ws[1].T) * self.relu_derivative(self.Z1))\n",
    "        dW1 = np.dot(self.X.T, self.dZ1) / m \n",
    "        dB1 = np.mean(self.dZ1, axis=0, keepdims = True) \n",
    "        \n",
    "        #adjusting weights and biases\n",
    "        self.Ws[0] = self.Ws[0] - self.learning_rate * dW1\n",
    "        self.biases[0] = self.biases[0] - self.learning_rate * dB1\n",
    "        self.Ws[1] = self.Ws[1] - self.learning_rate * dW2\n",
    "        self.biases[1] = self.biases[1] - self.learning_rate * dB2\n",
    "        self.Ws[2] = self.Ws[2] - self.learning_rate * dW3\n",
    "        self.biases[2] = self.biases[2] - self.learning_rate * dB3\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if(self.Verbose):\n",
    "            start = time.time()\n",
    "            print(\"Starts fitting ...\")\n",
    "        self.init_weights(X, y)\n",
    "        batches_amount = math.ceil(X.shape[0] / self.batch_size) # check to round up \n",
    "        for epoch in range(self.epochs):\n",
    "            shuffled_X, shuffled_y = self.shuffle_data(X, y)\n",
    "            for batch_idx in range(batches_amount):\n",
    "                batch_X, batch_y = self.get_batch(shuffled_X, shuffled_y, batch_idx)\n",
    "                self.feed_forward(batch_X)\n",
    "                self.back_backpropagation(batch_y)\n",
    "            if(self.Verbose):\n",
    "                error = self.cross_entropy(np.eye(self.nof_classes)[shuffled_y], self.feed_forward(shuffled_X))\n",
    "                print(f\"Epoch {epoch + 1} of {self.epochs} finished with error: {error:.5f}\")\n",
    "\n",
    "        if(self.Verbose):\n",
    "            end = time.time()\n",
    "            print(f\"finished fitting in {end-start:.2f} seconds.\")\n",
    "        return self.Ws, self.biases\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.feed_forward(X)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)  # Obtain predicted labels using the predict() method\n",
    "        accuracy = np.mean(predictions == y)  # Calculate accuracy by comparing predictions with true labels\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d0c75",
   "metadata": {},
   "source": [
    "# choose which dataset to load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e716d82",
   "metadata": {},
   "source": [
    "# 1. YOUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a105d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('MNIST-data.npy')\n",
    "y = np.load(\"MNIST-lables.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4585f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (X.shape[0], X.shape[1]*X.shape[2]))\n",
    "X = X / 255 # normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d643b6",
   "metadata": {},
   "source": [
    "# 2. 'MY' DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4820c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f41e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input data and target labels\n",
    "X = np.array(mnist.data, dtype='float32') / 255 # Convert to NumPy array and normalize\n",
    "y = np.array(mnist.target, dtype='int') # Convert to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5fb20",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5854800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = NeuralNetwork(batch_size = 16)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"run with score of: {score:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
